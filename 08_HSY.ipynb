{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controlling-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "right-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zscore(n, mu, std, M, alpha=0.05, tail_num=2):\n",
    "    se = std / np.sqrt(n)\n",
    "    return round((M - mu) / se, 2)\n",
    "\n",
    "def calculate_norm_portion(alpha, tail_num):\n",
    "    return round(stats.norm.ppf(1 - alpha/tail_num), 3)\n",
    "\n",
    "def hypothesis_tester_basic(n, mu, std, M, alpha=0.05, tail_num=2):\n",
    "    \n",
    "    z, cr = calculate_zscore(n, mu, std, M), calculate_norm_portion(alpha, tail_num)\n",
    "    \n",
    "    if tail_num == 2:\n",
    "        \n",
    "        rejection_decision = (z > cr) | (z < -1 * cr)\n",
    "        region = f'z > {cr} or z < -{cr}'\n",
    "        criteria = f'two tail, alpha {alpha}'\n",
    "        \n",
    "    elif tail_num == 1:\n",
    "        \n",
    "        if z > 0:\n",
    "        \n",
    "            rejection_decision = (z > cr)\n",
    "            region = f'z > {cr}'\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            rejection_decision = (z < -1 * cr)\n",
    "            region = f'z < -{cr}'\n",
    "        \n",
    "        criteria = f'one tail, alpha {alpha}'\n",
    "        \n",
    "    else:\n",
    "        print('Should use tail_num 1 or 2.')\n",
    "        return None\n",
    "            \n",
    "    print(f'[{criteria}] z_statistic:{z}, critical_region:{region}\\n=> null hypothesis rejection [{rejection_decision}]')\n",
    "    \n",
    "def calculate_cohens_d(mu, std, M):\n",
    "    return round(abs((M - mu) / std), 2)\n",
    "\n",
    "def calculate_stat_power(n, mu, std, M):\n",
    "    se = std / np.sqrt(n)\n",
    "    z = ((mu + 1.96 * se) - M) / se\n",
    "    return round(1 - stats.norm.cdf(z), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-wallace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "detected-lexington",
   "metadata": {},
   "source": [
    "# 유형\n",
    "1. 가설검정 단계에 따라, Treatment 효과(M - mu) 통계적 유의성(significance)를 판단하는 문제\n",
    "2. 단측(one-sided test) / 양측(two-sided test), 유의수준(alpha)에 따른 결과 차이 확인 문제\n",
    "3. cohens d를 구하는 문제\n",
    "4. 표준편차(sigma), 샘플 개수(n)에 따른 귀무가설(null hypothesis) 기각의 관계\n",
    "5. 통계적 검증력 (statistical power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-preservation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "stock-metallic",
   "metadata": {},
   "source": [
    "#### 세광님\n",
    "- cohens d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-shield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "antique-shoulder",
   "metadata": {},
   "source": [
    "### 가설검정 단계에 따라, Treatment 효과(M - mu) 통계적 유의성(significance)를 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-durham",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_06_01.png)\n",
    "\n",
    "![''](./08_src/08_06_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "considerable-drain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:1.33, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 16, 50, 12, 54\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-opportunity",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_07_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "responsible-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:-2.5, critical_region:-1.96 < z < 1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 64, 14, 4.8, 12.5\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-explanation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-surprise",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_08_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "mental-universe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:2.53, critical_region:-1.96 < z < 1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 100, 50, 15, 53.8\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "organic-logging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cohens_d(mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-collective",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "persistent-deposit",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_15_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cognitive-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:-1.2, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 36, 400, 40, 392\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "olive-stack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cohens_d(mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-damages",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "comparable-shore",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_18_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "coastal-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:2.31, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 16, 45, 9, 50.2\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fossil-procedure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cohens_d(mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "recovered-hydrogen",
   "metadata": {},
   "source": [
    "### 표준편차(sigma), 샘플 개수(n)에 따른 귀무가설(null hypothesis) 기각의 관계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-complement",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_09_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "considered-latin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:2.5, critical_region:-1.96 < z < 1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 36, 71, 12, 76\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "steady-chester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:1.67, critical_region:-1.96 < z < 1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 36, 71, 18, 76\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-chemistry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "focused-mountain",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_10_01.png)\n",
    "\n",
    "![''](./08_src/08_10_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "short-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:1.5, critical_region:-1.96 < z < 1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 16, 30, 8, 33\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "starting-conclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:3.0, critical_region:-1.96 < z < 1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 64, 30, 8, 33\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-addiction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-puzzle",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_11_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "confirmed-child",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:4.0, critical_region:-1.96 < z < 1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 25, 40, 5, 44\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "allied-quilt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:1.33, critical_region:-1.96 < z < 1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 25, 40, 15, 44\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-reward",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regulated-guyana",
   "metadata": {},
   "source": [
    "### 단측(one-sided test) / 양측(two-sided test), 유의수준(alpha)에 따른 결과 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-phase",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_12_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "scenic-candle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:2.6, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 36, 4.22, 0.6, 4.48\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "stretch-brain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[one tail, alpha 0.05] z_statistic:-1.75, critical_region:z < -1.645\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 25, 4.22, 0.6, 4.01\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M, alpha=0.05, tail_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-saint",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-death",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_14_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "stock-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.01] z_statistic:2.75, critical_region:z > 2.576 or z < -2.576\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 25, 400, 40, 422\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-federal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "stunning-craps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[one tail, alpha 0.01] z_statistic:2.75, critical_region:z > 2.326\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 25, 400, 40, 422\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M, alpha=0.01, tail_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-lyric",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "centered-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cohens_d(mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-rough",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-lover",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_16_01.png)\n",
    "\n",
    "![''](./08_src/08_16_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "monthly-basics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[one tail, alpha 0.05] z_statistic:2.79, critical_region:z > 1.645\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 4, 9.6, 1.9, 12.25\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M, alpha=0.05, tail_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-iraqi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "minus-alfred",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_17_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "major-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[one tail, alpha 0.01] z_statistic:2.77, critical_region:z > 2.326\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 20, 500, 100, 562\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M, alpha=0.01, tail_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "coated-collar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cohens_d(mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-pencil",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "convinced-confusion",
   "metadata": {},
   "source": [
    "### 통계적 검증력 (statistical power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-accounting",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_19_01.png)\n",
    "\n",
    "![''](./08_src/08_19_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "figured-liabilities",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:1.5, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 9, 40, 12, 46\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eastern-scholarship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3228"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_stat_power(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-telling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "miniature-stress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:2.0, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 16, 40, 12, 46\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "tamil-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.516"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_stat_power(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-adaptation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "interim-ranking",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_20_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "tutorial-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:-3.0, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "n, mu, std, M = 9, 240, 30, 210\n",
    "\n",
    "hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "hearing-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_stat_power(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "tired-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_stat_power(n, mu, std, M):\n",
    "se = std / np.sqrt(n)\n",
    "z = ((mu + -1.96 * se) - M) / se\n",
    "# return round(1 - stats.norm.cdf(z), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "encouraging-essay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220.4"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mu + -1.96 * se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "small-rating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0400000000000005"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "joined-miracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8508300496690187"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.norm.cdf(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-carter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-angola",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-pound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-wonder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-platinum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-benchmark",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
