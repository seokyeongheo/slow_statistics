{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "studied-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import slow_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-headset",
   "metadata": {},
   "source": [
    "# 유형\n",
    "1. 가설검정 단계에 따라, Treatment 효과(M - mu) 통계적 유의성(significance)를 판단하는 문제\n",
    "2. 단측(one-sided test) / 양측(two-sided test), 유의수준(alpha)에 따른 결과 차이 확인 문제\n",
    "3. cohens d를 구하는 문제\n",
    "4. 표준편차(sigma), 샘플 개수(n)에 따른 귀무가설(null hypothesis) 기각의 관계\n",
    "5. 통계적 검증력 (statistical power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-sentence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "classical-multimedia",
   "metadata": {},
   "source": [
    "#### 세광님\n",
    "- cohens d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-relaxation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-pantyhose",
   "metadata": {},
   "source": [
    "### 가설검정 단계에 따라, Treatment 효과(M - mu) 통계적 유의성(significance)를 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-young",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_06_01.png)\n",
    "\n",
    "![''](./08_src/08_06_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "about-marks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:1.33, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 16, 50, 12, 54\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-suspect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-mailman",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_07_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attractive-tutorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:-2.5, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 64, 14, 4.8, 12.5\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-contrary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "working-casting",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_08_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "educated-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:2.53, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 100, 50, 15, 53.8\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "civil-melbourne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_stat.cohens_d_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-gospel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "solid-copying",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_15_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "egyptian-hungary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:-1.2, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 36, 400, 40, 392\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacterial-insured",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_stat.cohens_d_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-analyst",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "breathing-rogers",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_18_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "automated-supply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:2.31, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 16, 45, 9, 50.2\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "norman-blank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_stat.cohens_d_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-citizen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-positive",
   "metadata": {},
   "source": [
    "### 표준편차(sigma), 샘플 개수(n)에 따른 귀무가설(null hypothesis) 기각의 관계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-missile",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_09_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rubber-object",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:2.5, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 36, 71, 12, 76\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ordered-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:1.67, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 36, 71, 18, 76\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-suggestion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ethical-worst",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_10_01.png)\n",
    "\n",
    "![''](./08_src/08_10_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hybrid-dining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:1.5, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 16, 30, 8, 33\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "developed-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:3.0, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 64, 30, 8, 33\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-overhead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-metadata",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-acrobat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "everyday-australia",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_11_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "revolutionary-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:4.0, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 25, 40, 5, 44\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "addressed-enough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:1.33, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [False]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 25, 40, 15, 44\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-sellers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-comparison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-superior",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "circular-gothic",
   "metadata": {},
   "source": [
    "### 단측(one-sided test) / 양측(two-sided test), 유의수준(alpha)에 따른 결과 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-yeast",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_12_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "expressed-front",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.05] z_statistic:2.6, critical_region:z > 1.96 or z < -1.96\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 36, 4.22, 0.6, 4.48\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fitted-opposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[one tail, alpha 0.05] z_statistic:2.6, critical_region:z > 1.645\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 36, 4.22, 0.6, 4.48\n",
    "slow_stat.tail_num = 1\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-basis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "falling-omaha",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_14_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "seeing-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[two tail, alpha 0.01] z_statistic:2.75, critical_region:z > 2.576 or z < -2.576\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 25, 400, 40, 422\n",
    "slow_stat.alpha = 0.01\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "impossible-teaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[one tail, alpha 0.01] z_statistic:2.75, critical_region:z > 2.326\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 25, 400, 40, 422\n",
    "slow_stat.alpha = 0.01\n",
    "slow_stat.tail_num = 1\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eleven-production",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_stat.cohens_d_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-treatment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "declared-stranger",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_16_01.png)\n",
    "\n",
    "![''](./08_src/08_16_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "advanced-thread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[one tail, alpha 0.05] z_statistic:2.79, critical_region:z > 1.645\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 4, 9.6, 1.9, 12.25\n",
    "slow_stat.tail_num = 1\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-fashion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "stylish-rocket",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_17_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "funny-consistency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[one tail, alpha 0.01] z_statistic:2.77, critical_region:z > 2.326\n",
      "=> null hypothesis rejection [True]\n"
     ]
    }
   ],
   "source": [
    "slow_stat = slow_statistic.Stats()\n",
    "\n",
    "slow_stat.n, slow_stat.mu, slow_stat.std, slow_stat.M = 20, 500, 100, 562\n",
    "slow_stat.alpha = 0.01\n",
    "slow_stat.tail_num = 1\n",
    "\n",
    "slow_stat.ztest_1samp_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "unsigned-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_stat.cohens_d_from_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-puppy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "solid-notion",
   "metadata": {},
   "source": [
    "### 통계적 검증력 (statistical power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-dublin",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_19_01.png)\n",
    "\n",
    "![''](./08_src/08_19_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "convinced-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n, mu, std, M = 9, 40, 12, 46\n",
    "\n",
    "# hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "copyrighted-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_stat_power(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "attractive-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n, mu, std, M = 16, 40, 12, 46\n",
    "\n",
    "# hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "distinguished-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_stat_power(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-bachelor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "documentary-silicon",
   "metadata": {},
   "source": [
    "---\n",
    "![''](./08_src/08_20_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "catholic-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n, mu, std, M = 9, 240, 30, 210\n",
    "\n",
    "# hypothesis_tester_basic(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ongoing-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_stat_power(n, mu, std, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "interior-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def calculate_stat_power(n, mu, std, M):\n",
    "# se = std / np.sqrt(n)\n",
    "# z = ((mu + -1.96 * se) - M) / se\n",
    "# # return round(1 - stats.norm.cdf(z), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ranging-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (mu + -1.96 * se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "potential-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.norm.cdf(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-recall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-drawing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-childhood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-qatar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-elder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
